{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_csv = r\"C:\\Users\\Alvin\\Desktop\\UT\\fall2019\\research project\\dep final proj\\CSV files\"\n",
    "filepath_audio = r\"C:\\Users\\Alvin\\Desktop\\UT\\fall2019\\research project\\dep final proj\\Audio files\"\n",
    "csv = os.listdir(filepath_csv)\n",
    "audio = os.listdir(filepath_audio)\n",
    "\n",
    "csvpath = []\n",
    "for csv in csv:\n",
    "    name = filepath_csv + \"\\\\\" + csv\n",
    "    csvpath.append(name)\n",
    "    \n",
    "audiopath = []\n",
    "for audio in audio:\n",
    "    name = filepath_audio + \"\\\\\" + audio\n",
    "    audiopath.append(name)\n",
    "    \n",
    "# combine audio and annotation file paths in a list\n",
    "# make sure length of list1 is smaller or equal to list2\n",
    "\n",
    "def combo(csvpath, audiopath):\n",
    "    file = []\n",
    "    for i in range(0,len(csvpath)):\n",
    "        combine = []\n",
    "        combine.append(csvpath[i])\n",
    "        combine.append(audiopath[i])\n",
    "        file.append(combine)\n",
    "    return file\n",
    "\n",
    "filepath = combo(csvpath, audiopath)\n",
    "labelpath = r\"C:\\Users\\Alvin\\Desktop\\UT\\fall2019\\research project\\dep final proj\\dep_QIDS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert original annotated csv files into the format we want \n",
    "def convert_csv(csvpath):\n",
    "    df = pd.read_csv(csvpath, header=None)\n",
    "    if df.shape[1]==8:\n",
    "        df=df.iloc[:,1:]\n",
    "    elif df.shape[1]==9:\n",
    "        df=df.iloc[:,2:]\n",
    "    col_name=[\"start\",\"start_sec\",\"end\",\"end_sec\",\"duration\", \"duration_sec\",\"interviewer\"]\n",
    "    df.columns=col_name\n",
    "    # convert columns\n",
    "    start=[i for i in df[df.interviewer==\"Interviewee\"].start_sec]\n",
    "    end=[i for i in df[df.interviewer==\"Interviewee\"].end_sec]\n",
    "    duration=[end[i]-start[i] for i in range(0,len(start))]\n",
    "    cumulative=[sum(duration[:i]) for i in range(1, len(duration)+1)]\n",
    "    start_trans=[i/df[df.interviewer==\"Interviewer\"].end_sec[-1:] for i in start]\n",
    "    start_trans=[i/float(df[df.interviewer==\"Interviewer\"].end_sec[-1:]) for i in start]\n",
    "    end_trans=[i/float(df[df.interviewer==\"Interviewer\"].end_sec[-1:]) for i in end]\n",
    "    # put new columns in new data frame\n",
    "    df1 = pd.DataFrame({\"start\": start, \"end\": end, \"duration\": duration, \"cumulative\": cumulative,\n",
    "                    \"start_trans\": start_trans, \"end_trans\": end_trans, \"participant\":\"interviewee_speaking\"})\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map annotated csv episodes to audio input for mapped array and sampling rate\n",
    "def mapped_array_sr(dataframe, audiopath):\n",
    "    start = [x for x in dataframe.start_trans]\n",
    "    end = [x for x in dataframe.end_trans]\n",
    "    y, sr = librosa.load(audiopath, sr=None)\n",
    "    emp=np.array([])\n",
    "    for i in range(0,len(start)):  \n",
    "        y_start = int(start[i]*len(y))\n",
    "        y_end = int(end[i]*len(y))\n",
    "        y_new = y[y_start-1:y_end-1]\n",
    "        emp=np.append(emp, y_new)\n",
    "    new_array=emp[1:]\n",
    "    return new_array, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to extract acoustic features\n",
    "def mfccs_(y, sr, n_mfcc, hop_size, window_size):\n",
    "    mfccs = librosa.feature.mfcc(y, sr, n_mfcc=n_mfcc, hop_length=int(hop_size*sr), n_fft=int(window_size*sr))\n",
    "    mfcc_name=[]\n",
    "    for i in range(0,len(mfccs[:,0])):\n",
    "        title = \"mfcc\" + str(i+1)\n",
    "        mfcc_name.append(title)\n",
    "    mfccs = mfccs.transpose()\n",
    "    return mfccs, mfcc_name\n",
    "\n",
    "def picthes_magnitudes(y, sr, hop_size, window_size):\n",
    "    pitches, magnitudes = librosa.piptrack(y, sr, hop_length=int(hop_size*sr), n_fft=int(window_size*sr))\n",
    "    pitches = pitches.transpose()\n",
    "    magnitudes = magnitudes.transpose()\n",
    "    pitch = []\n",
    "    magnitude = []\n",
    "    for i in range(0,len(pitches[:,])):\n",
    "        pitch.append(pitches[i,].mean())\n",
    "    for i in range(0,len(magnitudes[:,])):\n",
    "        magnitude.append(magnitudes[i,].mean())\n",
    "    return pitch, magnitude\n",
    "\n",
    "def chroma_energy_mean(y, sr):\n",
    "    chroma = librosa.feature.chroma_cens(y, sr)\n",
    "    chroma_energy_mean = chroma.mean()\n",
    "    return chroma_energy_mean\n",
    "\n",
    "def zero_cross(y, sr, hop_size):\n",
    "    zero_cross = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=int(hop_size*sr), center=True)\n",
    "    zero_cross = zero_cross.transpose()\n",
    "    return zero_cross\n",
    "\n",
    "def mel_freq_spec(y, sr, hop_size, window_size, n_mels):\n",
    "    spec = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=int(hop_size*sr), n_fft=int(window_size*sr), n_mels=n_mels)\n",
    "    db_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    mel_freq = db_spec.transpose()\n",
    "    mel_name=[]\n",
    "    for i in range(0,len(mel_freq[0,:])):\n",
    "        title = \"mel_freq\" + str(i+1)\n",
    "        mel_name.append(title)\n",
    "    return mel_freq, mel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get structured features and label \n",
    "def format_features(filepath, labelpath):\n",
    "    # add label \n",
    "    df_label = pd.read_csv(labelpath)\n",
    "    df_label = df_label[df_label.Available.isna()==False]\n",
    "    df_label = df_label[\"Record ID\"]\n",
    "    # add features\n",
    "    features = [\"mfcc1\", \"mfcc2\", \"mfcc3\", \"mfcc4\", \"mfcc5\", \"mfcc6\", \"mfcc7\", \"mfcc8\", \"mfcc9\", \"mfcc10\", \"mfcc11\",\n",
    "                \"mfcc12\",\"mfcc13\", \"mel_freq1\",\"mel_freq2\",\"mel_freq3\",\"mel_freq4\",\"mel_freq5\",\"mel_freq6\",\"mel_freq7\",\"mel_freq8\",\n",
    "                \"Record ID\", \"pitch\",\"magnitude\",\"chroma_ener_avg\", \"zero_cross_rate\"]\n",
    "    df_emp = pd.DataFrame(columns=features)\n",
    "    nrow = []\n",
    "    # get features by calling above functions\n",
    "    for name in filepath:\n",
    "        frame = convert_csv(name[0])\n",
    "        new_array, sr = mapped_array_sr(frame, name[1])\n",
    "        mfcc, mfcc_name = mfccs_(new_array, sr, 13, 0.03, 0.06)\n",
    "        mel_freq, mel_name = mel_freq_spec(new_array, sr, 0.03, 0.06, 8)\n",
    "        pitch, magnitude = picthes_magnitudes(new_array, sr, 0.03, 0.06)\n",
    "        chroma_ener_mean = chroma_energy_mean(new_array, sr)\n",
    "        zero_crs = zero_cross(new_array, sr, 0.03)\n",
    "        # create pandas dataframe \n",
    "        df_iter = pd.DataFrame(mfcc, columns=mfcc_name)\n",
    "        df_mel = pd.DataFrame(mel_freq, columns=mel_name)\n",
    "        df = pd.concat([df_iter, df_mel], axis=1)\n",
    "        df[\"Record ID\"] = int(name[1][-8:-4])\n",
    "        df[\"pitch\"] = pitch\n",
    "        df[\"magnitude\"] = magnitude\n",
    "        df[\"chroma_ener_avg\"] = chroma_ener_mean\n",
    "        df[\"zero_cross_rate\"] = zero_crs\n",
    "        df_emp = pd.concat([df_emp, df], axis=0, ignore_index=True)\n",
    "        # get each participant row end position\n",
    "        row_n = len(mfcc[:,0])\n",
    "        nrow.append(row_n)\n",
    "    # get delta of features\n",
    "    for i in list(df_emp.columns):\n",
    "        if \"Record ID\" not in i:\n",
    "            name=i+\"_delta\"\n",
    "            df_emp[name]=float(0)\n",
    "            for j in range(1, len(df_emp)):\n",
    "                df_emp[name][j]=float(df_emp[i][j]) - float(df_emp[i][j-1])\n",
    "    # combine features and label\n",
    "    df_emp = df_emp.merge(df_label, on=\"Record ID\")\n",
    "    df_emp[\"Record Id\"] = df_emp[\"Record ID\"]\n",
    "    df_emp.drop([\"Record ID\"], axis=1, inplace=True)\n",
    "    return df_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = format_features(filepath, labelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save formatted features with participant Id to a csv file \n",
    "df.to_csv(r\"C:\\Users\\Alvin\\Desktop\\UT\\fall2019\\research project\\dep final proj\\CBT_LLLT_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
